{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shlokster/Lecture-Summariser/blob/main/IT204_Lecture_summariser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAuBao_9waUJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "from io import BytesIO\n",
        "!pip -q install pydub\n",
        "!pip install pyaudio\n",
        "!pip install SpeechRecognition\n",
        "\n",
        "from pydub import AudioSegment\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=3):\n",
        "  display(Javascript(RECORD))\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  audio = AudioSegment.from_file(BytesIO(b))\n",
        "  return audio"
      ],
      "metadata": {
        "id": "OJIQx4XRDEc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a654c2e-0487-47fc-9296-bff375dc4b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyaudio\n",
            "  Downloading PyAudio-0.2.11.tar.gz (37 kB)\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pyaudio\n",
            "Failed to build pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "    Running setup.py install for pyaudio ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-4jwhvyv9/pyaudio_b10f57b47f7b44719b794d078b41bf67/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-4jwhvyv9/pyaudio_b10f57b47f7b44719b794d078b41bf67/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-ghgybl7d/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/pyaudio Check the logs for full command output.\u001b[0m\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 1.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "import sys\n",
        "\n",
        "#read duration from the arguments\n",
        "duration = int(5)\n",
        "\n",
        "# initialize the recognizer\n",
        "r = sr.Recognizer()\n",
        "print(sr.Microphone.list_microphone_names())\n",
        "print(\"Please talk\")\n",
        "with sr.Microphone() as source:\n",
        "    # read the audio data from the default microphone\n",
        "    audio_data = r.record(source, duration=duration)\n",
        "    print(\"Recognizing...\")\n",
        "    # convert speech to text\n",
        "    text = r.recognize_google(audio_data)\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "Y0mu3_mB235a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "e1668dab-0cf1-4da2-ea1c-973d54f9e55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mget_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-01a781bb2cb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# initialize the recognizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_microphone_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please talk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mlist_microphone_names\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0meach\u001b[0m \u001b[0mmicrophone\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mits\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mcreating\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevice_index\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMicrophone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pyaudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mget_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not find PyAudio; check installation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.2.11\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Could not find PyAudio; check installation"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSA- SVD Implementation"
      ],
      "metadata": {
        "id": "2Of6jdnGc5pZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Gjfb0vLiBj3",
        "outputId": "3778082d-c290-4992-95f8-50431933e365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sumy\n",
            "  Downloading sumy-0.10.0-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting pycountry>=18.2.23\n",
            "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 34.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from sumy) (2.23.0)\n",
            "Collecting breadability>=0.1.20\n",
            "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from sumy) (3.2.5)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from breadability>=0.1.20->sumy) (3.0.4)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.7/dist-packages (from breadability>=0.1.20->sumy) (4.2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.0.2->sumy) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pycountry>=18.2.23->sumy) (57.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (2021.10.8)\n",
            "Building wheels for collected packages: breadability, pycountry\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21712 sha256=e94a8ad56c796fc04b39e750b1142c112d02925c248f3435d8e7922300b2c639\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/bf/51/81d27ad638e1a6dca4f362ecc33d1e2c764b8ea7ec751b8fc1\n",
            "  Building wheel for pycountry (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681845 sha256=c9c1b5d02059b1d470f8ea96480160bedc892fc3bf8fb0d3a3a3e7a770238797\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/06/e8/7ee176e95ea9a8a8c3b3afcb1869f20adbd42413d4611c6eb4\n",
            "Successfully built breadability pycountry\n",
            "Installing collected packages: pycountry, breadability, sumy\n",
            "Successfully installed breadability-0.1.20 pycountry-22.3.5 sumy-0.10.0\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Junk foods taste good that’s why it is mostly liked by everyone of any age group especially kids and school going children.\n",
            "To make things worse, junk food also clogs your arteries and increases the risk of a heart attack.\n",
            "Therefore, it must be avoided at the first instance to save your life from becoming ruined.The main problem with junk food is that people don’t realize its ill effects now.\n"
          ]
        }
      ],
      "source": [
        "!pip install sumy\n",
        "# Import the summarizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "# Text to summarize\n",
        "original_text = 'Junk foods taste good that’s why it is mostly liked by everyone of any age group especially kids and school going children. They generally ask for the junk food daily because they have been trend so by their parents from the childhood. They never have been discussed by their parents about the harmful effects of junk foods over health. According to the research by scientists, it has been found that junk foods have negative effects on the health in many ways. They are generally fried food found in the market in the packets. They become high in calories, high in cholesterol, low in healthy nutrients, high in sodium mineral, high in sugar, starch, unhealthy fat, lack of protein and lack of dietary fibers. Processed and junk foods are the means of rapid and unhealthy weight gain and negatively impact the whole body throughout the life. It makes able a person to gain excessive weight which is called as obesity. Junk foods tastes good and looks good however do not fulfil the healthy calorie requirement of the body. Some of the foods like french fries, fried foods, pizza, burgers, candy, soft drinks, baked goods, ice cream, cookies, etc are the example of high-sugar and high-fat containing foods. It is found according to the Centres for Disease Control and Prevention that Kids and children eating junk food are more prone to the type-2 diabetes. In type-2 diabetes our body become unable to regulate blood sugar level. Risk of getting this disease is increasing as one become more obese or overweight. It increases the risk of kidney failure. Eating junk food daily lead us to the nutritional deficiencies in the body because it is lack of essential nutrients, vitamins, iron, minerals and dietary fibers. It increases risk of cardiovascular diseases because it is rich in saturated fat, sodium and bad cholesterol. High sodium and bad cholesterol diet increases blood pressure and overloads the heart functioning. One who like junk food develop more risk to put on extra weight and become fatter and unhealthier. Junk foods contain high level carbohydrate which spike blood sugar level and make person more lethargic, sleepy and less active and alert. Reflexes and senses of the people eating this food become dull day by day thus they live more sedentary life. Junk foods are the source of constipation and other disease like diabetes, heart ailments, clogged arteries, heart attack, strokes, etc because of being poor in nutrition. Junk food is the easiest way to gain unhealthy weight. The amount of fats and sugar in the food makes you gain weight rapidly. However, this is not a healthy weight. It is more of fats and cholesterol which will have a harmful impact on your health. Junk food is also one of the main reasons for the increase in obesity nowadays.This food only looks and tastes good, other than that, it has no positive points. The amount of calorie your body requires to stay fit is not fulfilled by this food. For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats. Therefore, this can result in long-term illnesses like diabetes and high blood pressure. This may also result in kidney failure. Above all, you can get various nutritional deficiencies when you don’t consume the essential nutrients, vitamins, minerals and more. You become prone to cardiovascular diseases due to the consumption of bad cholesterol and fat plus sodium. In other words, all this interferes with the functioning of your heart. Furthermore, junk food contains a higher level of carbohydrates. It will instantly spike your blood sugar levels. This will result in lethargy, inactiveness, and sleepiness. A person reflex becomes dull overtime and they lead an inactive life. To make things worse, junk food also clogs your arteries and increases the risk of a heart attack. Therefore, it must be avoided at the first instance to save your life from becoming ruined.The main problem with junk food is that people don’t realize its ill effects now. When the time comes, it is too late. Most importantly, the issue is that it does not impact you instantly. It works on your overtime; you will face the consequences sooner or later. Thus, it is better to stop now.You can avoid junk food by encouraging your children from an early age to eat green vegetables. Their taste buds must be developed as such that they find healthy food tasty. Moreover, try to mix things up. Do not serve the same green vegetable daily in the same style. Incorporate different types of healthy food in their diet following different recipes. This will help them to try foods at home rather than being attracted to junk food.In short, do not deprive them completely of it as that will not help. Children will find one way or the other to have it. Make sure you give them junk food in limited quantities and at healthy periods of time. '\n",
        "import nltk\n",
        "nltk.download('punkt')# Parsing the text string using PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "parser=PlaintextParser.from_string(original_text,Tokenizer('english'))\n",
        "\n",
        "# creating the summarizer\n",
        "lsa_summarizer=LsaSummarizer()\n",
        "lsa_summary= lsa_summarizer(parser.document,3)\n",
        "\n",
        "# Printing the summary\n",
        "for sentence in lsa_summary:\n",
        " print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NdwvMiYwyXs"
      },
      "source": [
        "TF-IDF Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf78-rkrk_IR",
        "outputId": "04d2418e-961c-46db-9c22-9931bdc6ba37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "/bin/bash: -c: line 0: syntax error near unexpected token `'punkt''\n",
            "/bin/bash: -c: line 0: `nltk.download('punkt')'\n",
            "/bin/bash: -c: line 0: syntax error near unexpected token `'stopwords''\n",
            "/bin/bash: -c: line 0: `nltk.download('stopwords')'\n",
            "/bin/bash: -c: line 0: syntax error near unexpected token `'popular''\n",
            "/bin/bash: -c: line 0: `nltk.download('popular')'\n",
            " They are generally fried food found in the market in the packets. It increases the risk of kidney failure. It is more of fats and cholesterol which will have a harmful impact on your health. This may also result in kidney failure. It will instantly spike your blood sugar levels. When the time comes, it is too late. Most importantly, the issue is that it does not impact you instantly. It works on your overtime; you will face the consequences sooner or later. Moreover, try to mix things up. Do not serve the same green vegetable daily in the same style. Incorporate different types of healthy food in their diet following different recipes. Children will find one way or the other to have it.\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "# Setup\n",
        "!pip install -q wordcloud\n",
        "import wordcloud\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import math\n",
        "import nltk\n",
        "!nltk.download('punkt')\n",
        "!nltk.download('stopwords')\n",
        "!nltk.download('popular')\n",
        "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "text_str = '''Junk foods taste good that’s why it is mostly liked by everyone of any age group especially kids and school going children. They generally ask for the junk food daily because they have been trend so by their parents from the childhood. They never have been discussed by their parents about the harmful effects of junk foods over health. According to the research by scientists, it has been found that junk foods have negative effects on the health in many ways. They are generally fried food found in the market in the packets. They become high in calories, high in cholesterol, low in healthy nutrients, high in sodium mineral, high in sugar, starch, unhealthy fat, lack of protein and lack of dietary fibers. Processed and junk foods are the means of rapid and unhealthy weight gain and negatively impact the whole body throughout the life. It makes able a person to gain excessive weight which is called as obesity. Junk foods tastes good and looks good however do not fulfil the healthy calorie requirement of the body. Some of the foods like french fries, fried foods, pizza, burgers, candy, soft drinks, baked goods, ice cream, cookies, etc are the example of high-sugar and high-fat containing foods. It is found according to the Centres for Disease Control and Prevention that Kids and children eating junk food are more prone to the type-2 diabetes. In type-2 diabetes our body become unable to regulate blood sugar level. Risk of getting this disease is increasing as one become more obese or overweight. It increases the risk of kidney failure. Eating junk food daily lead us to the nutritional deficiencies in the body because it is lack of essential nutrients, vitamins, iron, minerals and dietary fibers. It increases risk of cardiovascular diseases because it is rich in saturated fat, sodium and bad cholesterol. High sodium and bad cholesterol diet increases blood pressure and overloads the heart functioning. One who like junk food develop more risk to put on extra weight and become fatter and unhealthier. Junk foods contain high level carbohydrate which spike blood sugar level and make person more lethargic, sleepy and less active and alert. Reflexes and senses of the people eating this food become dull day by day thus they live more sedentary life. Junk foods are the source of constipation and other disease like diabetes, heart ailments, clogged arteries, heart attack, strokes, etc because of being poor in nutrition. Junk food is the easiest way to gain unhealthy weight. The amount of fats and sugar in the food makes you gain weight rapidly. However, this is not a healthy weight. It is more of fats and cholesterol which will have a harmful impact on your health. Junk food is also one of the main reasons for the increase in obesity nowadays.This food only looks and tastes good, other than that, it has no positive points. The amount of calorie your body requires to stay fit is not fulfilled by this food. For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats. Therefore, this can result in long-term illnesses like diabetes and high blood pressure. This may also result in kidney failure. Above all, you can get various nutritional deficiencies when you don’t consume the essential nutrients, vitamins, minerals and more. You become prone to cardiovascular diseases due to the consumption of bad cholesterol and fat plus sodium. In other words, all this interferes with the functioning of your heart. Furthermore, junk food contains a higher level of carbohydrates. It will instantly spike your blood sugar levels. This will result in lethargy, inactiveness, and sleepiness. A person reflex becomes dull overtime and they lead an inactive life. To make things worse, junk food also clogs your arteries and increases the risk of a heart attack. Therefore, it must be avoided at the first instance to save your life from becoming ruined.The main problem with junk food is that people don’t realize its ill effects now. When the time comes, it is too late. Most importantly, the issue is that it does not impact you instantly. It works on your overtime; you will face the consequences sooner or later. Thus, it is better to stop now.You can avoid junk food by encouraging your children from an early age to eat green vegetables. Their taste buds must be developed as such that they find healthy food tasty. Moreover, try to mix things up. Do not serve the same green vegetable daily in the same style. Incorporate different types of healthy food in their diet following different recipes. This will help them to try foods at home rather than being attracted to junk food.In short, do not deprive them completely of it as that will not help. Children will find one way or the other to have it. Make sure you give them junk food in limited quantities and at healthy periods of time.'''\n",
        "\n",
        "\n",
        "def _create_frequency_table(text_string) -> dict:\n",
        "    \"\"\"\n",
        "    we create a dictionary for the word frequency table.\n",
        "    For this, we should only use the words that are not part of the stopWords array.\n",
        "    Removing stop words and making frequency table\n",
        "    Stemmer - an algorithm to bring words to its root word.\n",
        "    :rtype: dict\n",
        "    \"\"\"\n",
        "    stopWords = set(stopwords.words(\"english\"))\n",
        "    words = word_tokenize(text_string)\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "    freqTable = dict()\n",
        "    for word in words:\n",
        "        word = ps.stem(word)\n",
        "        if word in stopWords:\n",
        "            continue\n",
        "        if word in freqTable:\n",
        "            freqTable[word] += 1\n",
        "        else:\n",
        "            freqTable[word] = 1\n",
        "\n",
        "    return freqTable\n",
        "\n",
        "\n",
        "def _create_frequency_matrix(sentences):\n",
        "    frequency_matrix = {}\n",
        "    stopWords = set(stopwords.words(\"english\"))\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "    for sent in sentences:\n",
        "        freq_table = {}\n",
        "        words = word_tokenize(sent)\n",
        "        for word in words:\n",
        "            word = word.lower()\n",
        "            word = ps.stem(word)\n",
        "            if word in stopWords:\n",
        "                continue\n",
        "\n",
        "            if word in freq_table:\n",
        "                freq_table[word] += 1\n",
        "            else:\n",
        "                freq_table[word] = 1\n",
        "\n",
        "        frequency_matrix[sent[:15]] = freq_table\n",
        "\n",
        "    return frequency_matrix\n",
        "\n",
        "\n",
        "def _create_tf_matrix(freq_matrix):\n",
        "    tf_matrix = {}\n",
        "\n",
        "    for sent, f_table in freq_matrix.items():\n",
        "        tf_table = {}\n",
        "\n",
        "        count_words_in_sentence = len(f_table)\n",
        "        for word, count in f_table.items():\n",
        "            tf_table[word] = count / count_words_in_sentence\n",
        "\n",
        "        tf_matrix[sent] = tf_table\n",
        "\n",
        "    return tf_matrix\n",
        "\n",
        "\n",
        "def _create_documents_per_words(freq_matrix):\n",
        "    word_per_doc_table = {}\n",
        "\n",
        "    for sent, f_table in freq_matrix.items():\n",
        "        for word, count in f_table.items():\n",
        "            if word in word_per_doc_table:\n",
        "                word_per_doc_table[word] += 1\n",
        "            else:\n",
        "                word_per_doc_table[word] = 1\n",
        "\n",
        "    return word_per_doc_table\n",
        "\n",
        "\n",
        "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
        "    idf_matrix = {}\n",
        "\n",
        "    for sent, f_table in freq_matrix.items():\n",
        "        idf_table = {}\n",
        "\n",
        "        for word in f_table.keys():\n",
        "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
        "\n",
        "        idf_matrix[sent] = idf_table\n",
        "\n",
        "    return idf_matrix\n",
        "\n",
        "\n",
        "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
        "    tf_idf_matrix = {}\n",
        "\n",
        "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
        "\n",
        "        tf_idf_table = {}\n",
        "\n",
        "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
        "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
        "            tf_idf_table[word1] = float(value1 * value2)\n",
        "\n",
        "        tf_idf_matrix[sent1] = tf_idf_table\n",
        "\n",
        "    return tf_idf_matrix\n",
        "\n",
        "\n",
        "def _score_sentences(tf_idf_matrix) -> dict:\n",
        "    \"\"\"\n",
        "    score a sentence by its word's TF\n",
        "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
        "    :rtype: dict\n",
        "    \"\"\"\n",
        "\n",
        "    sentenceValue = {}\n",
        "\n",
        "    for sent, f_table in tf_idf_matrix.items():\n",
        "        total_score_per_sentence = 0\n",
        "\n",
        "        count_words_in_sentence = len(f_table)\n",
        "        for word, score in f_table.items():\n",
        "            total_score_per_sentence += score\n",
        "\n",
        "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
        "\n",
        "    return sentenceValue\n",
        "\n",
        "\n",
        "def _find_average_score(sentenceValue) -> int:\n",
        "    \"\"\"\n",
        "    Find the average score from the sentence value dictionary\n",
        "    :rtype: int\n",
        "    \"\"\"\n",
        "    sumValues = 0\n",
        "    for entry in sentenceValue:\n",
        "        sumValues += sentenceValue[entry]\n",
        "\n",
        "    # Average value of a sentence from original summary_text\n",
        "    average = (sumValues / len(sentenceValue))\n",
        "\n",
        "    return average\n",
        "\n",
        "\n",
        "def _generate_summary(sentences, sentenceValue, threshold):\n",
        "    sentence_count = 0\n",
        "    summary = ''\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if sentence[:15] in sentenceValue and sentenceValue[sentence[:15]] >= (threshold):\n",
        "            summary += \" \" + sentence\n",
        "            sentence_count += 1\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "def run_summarization(text):\n",
        "    \"\"\"\n",
        "    :param text: Plain summary_text of long article\n",
        "    :return: summarized summary_text\n",
        "    \"\"\"\n",
        "\n",
        "    '''\n",
        "    We already have a sentence tokenizer, so we just need \n",
        "    to run the sent_tokenize() method to create the array of sentences.\n",
        "    '''\n",
        "    # 1 Sentence Tokenize\n",
        "    sentences = sent_tokenize(text)\n",
        "    total_documents = len(sentences)\n",
        "    #print(sentences)\n",
        "\n",
        "    # 2 Create the Frequency matrix of the words in each sentence.\n",
        "    freq_matrix = _create_frequency_matrix(sentences)\n",
        "    #print(freq_matrix)\n",
        "\n",
        "    '''\n",
        "    Term frequency (TF) is how often a word appears in a document, divided by how many words are there in a document.\n",
        "    '''\n",
        "    # 3 Calculate TermFrequency and generate a matrix\n",
        "    tf_matrix = _create_tf_matrix(freq_matrix)\n",
        "    #print(tf_matrix)\n",
        "\n",
        "    # 4 creating table for documents per words\n",
        "    count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
        "    #print(count_doc_per_words)\n",
        "\n",
        "    '''\n",
        "    Inverse document frequency (IDF) is how unique or rare a word is.\n",
        "    '''\n",
        "    # 5 Calculate IDF and generate a matrix\n",
        "    idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
        "    #print(idf_matrix)\n",
        "\n",
        "    # 6 Calculate TF-IDF and generate a matrix\n",
        "    tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
        "    #print(tf_idf_matrix)\n",
        "\n",
        "    # 7 Important Algorithm: score the sentences\n",
        "    sentence_scores = _score_sentences(tf_idf_matrix)\n",
        "    #print(sentence_scores)\n",
        "\n",
        "    # 8 Find the threshold\n",
        "    threshold = _find_average_score(sentence_scores)\n",
        "    #print(threshold)\n",
        "\n",
        "    # 9 Important Algorithm: Generate the summary\n",
        "    summary = _generate_summary(sentences, sentence_scores, 1.3 * threshold)\n",
        "    return summary\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    result = run_summarization(text_str)\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqfQLlrEw3yp"
      },
      "source": [
        "Cosine Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvEeqGCWlrT6"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        " \n",
        "def read_article(file_name):\n",
        "    file = open(file_name, \"r\")\n",
        "    filedata = file.readlines()\n",
        "    article = filedata[0].split(\". \")\n",
        "    sentences = []\n",
        "\n",
        "    for sentence in article:\n",
        "        print(sentence)\n",
        "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
        "    sentences.pop() \n",
        "    \n",
        "    return sentences\n",
        "\n",
        "def sentence_similarity(sent1, sent2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        " \n",
        "    sent1 = [w.lower() for w in sent1]\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        " \n",
        "    all_words = list(set(sent1 + sent2))\n",
        " \n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        " \n",
        "    # build the vector for the first sentence\n",
        "    for w in sent1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector1[all_words.index(w)] += 1\n",
        " \n",
        "    # build the vector for the second sentence\n",
        "    for w in sent2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector2[all_words.index(w)] += 1\n",
        " \n",
        "    return 1 - cosine_distance(vector1, vector2)\n",
        " \n",
        "def build_similarity_matrix(sentences, stop_words):\n",
        "    # Create an empty similarity matrix\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        " \n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "            if idx1 == idx2: #ignore if both are same sentences\n",
        "                continue \n",
        "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "\n",
        "def generate_summary(file_name, top_n=5):\n",
        "    nltk.download(\"stopwords\")\n",
        "    stop_words = stopwords.words('english')\n",
        "    summarize_text = []\n",
        "\n",
        "    # Step 1 - Read text anc split it\n",
        "    sentences =  read_article('base.txt')\n",
        "\n",
        "    # Step 2 - Generate Similary Martix across sentences\n",
        "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
        "\n",
        "    # Step 3 - Rank sentences in similarity martix\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "    # Step 4 - Sort the rank and pick top sentences\n",
        "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
        "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
        "\n",
        "    for i in range(top_n):\n",
        "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "    # Step 5 - Offcourse, output the summarize text\n",
        "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n",
        "\n",
        "# let's begin\n",
        "generate_summary( \"sample.txt\", 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQBUtYUT4p2w"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "TextRank Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDifICllGAlQ",
        "outputId": "697e2a2e-a2fb-4df5-bff8-318009d05a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Eating junk food daily lead us to the nutritional deficiencies in the body because it is lack of essential nutrients, vitamins, iron, minerals and dietary fibers.', 'Junk food is also one of the main reasons for the increase in obesity nowadays.This food only looks and tastes good, other than that, it has no positive points.', 'To make things worse, junk food also clogs your arteries and increases the risk of a heart attack.', 'The amount of fats and sugar in the food makes you gain weight rapidly.', 'It is found according to the Centres for Disease Control and Prevention that Kids and children eating junk food are more prone to the type-2 diabetes.']\n"
          ]
        }
      ],
      "source": [
        "Zimport re\n",
        "\n",
        "import numpy as np\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "\n",
        "from nltk.cluster.util import cosine_distance\n",
        "\n",
        "MULTIPLE_WHITESPACE_PATTERN = re.compile(r\"\\s+\", re.UNICODE)\n",
        "\n",
        "\n",
        "def normalize_whitespace(text):\n",
        "    \"\"\"\n",
        "    Translates multiple whitespace into single space character.\n",
        "    If there is at least one new line character chunk is replaced\n",
        "    by single LF (Unix new line) character.\n",
        "    \"\"\"\n",
        "    return MULTIPLE_WHITESPACE_PATTERN.sub(_replace_whitespace, text)\n",
        "\n",
        "\n",
        "def _replace_whitespace(match):\n",
        "    text = match.group()\n",
        "\n",
        "    if \"\\n\" in text or \"\\r\" in text:\n",
        "        return \"\\n\"\n",
        "    else:\n",
        "        return \" \"\n",
        "\n",
        "\n",
        "def is_blank(string):\n",
        "    \"\"\"\n",
        "    Returns `True` if string contains only white-space characters\n",
        "    or is empty. Otherwise `False` is returned.\n",
        "    \"\"\"\n",
        "    return not string or string.isspace()\n",
        "\n",
        "\n",
        "def get_symmetric_matrix(matrix):\n",
        "    \"\"\"\n",
        "    Get Symmetric matrix\n",
        "    :param matrix:\n",
        "    :return: matrix\n",
        "    \"\"\"\n",
        "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
        "\n",
        "\n",
        "def core_cosine_similarity(vector1, vector2):\n",
        "    \"\"\"\n",
        "    measure cosine similarity between two vectors\n",
        "    :param vector1:\n",
        "    :param vector2:\n",
        "    :return: 0 < cosine similarity value < 1\n",
        "    \"\"\"\n",
        "    return 1 - cosine_distance(vector1, vector2)\n",
        "\n",
        "\n",
        "'''\n",
        "Note: This is not a summarization algorithm. This Algorithm pics top sentences irrespective of the order they appeared.\n",
        "'''\n",
        "\n",
        "\n",
        "class TextRank4Sentences():\n",
        "    def __init__(self):\n",
        "        self.damping = 0.85  # damping coefficient, usually is .85\n",
        "        self.min_diff = 1e-5  # convergence threshold\n",
        "        self.steps = 100  # iteration steps\n",
        "        self.text_str = None\n",
        "        self.sentences = None\n",
        "        self.pr_vector = None\n",
        "\n",
        "    def _sentence_similarity(self, sent1, sent2, stopwords=None):\n",
        "        if stopwords is None:\n",
        "            stopwords = []\n",
        "\n",
        "        sent1 = [w.lower() for w in sent1]\n",
        "        sent2 = [w.lower() for w in sent2]\n",
        "\n",
        "        all_words = list(set(sent1 + sent2))\n",
        "\n",
        "        vector1 = [0] * len(all_words)\n",
        "        vector2 = [0] * len(all_words)\n",
        "\n",
        "        # build the vector for the first sentence\n",
        "        for w in sent1:\n",
        "            if w in stopwords:\n",
        "                continue\n",
        "            vector1[all_words.index(w)] += 1\n",
        "\n",
        "        # build the vector for the second sentence\n",
        "        for w in sent2:\n",
        "            if w in stopwords:\n",
        "                continue\n",
        "            vector2[all_words.index(w)] += 1\n",
        "\n",
        "        return core_cosine_similarity(vector1, vector2)\n",
        "\n",
        "    def _build_similarity_matrix(self, sentences, stopwords=None):\n",
        "        # create an empty similarity matrix\n",
        "        sm = np.zeros([len(sentences), len(sentences)])\n",
        "\n",
        "        for idx1 in range(len(sentences)):\n",
        "            for idx2 in range(len(sentences)):\n",
        "                if idx1 == idx2:\n",
        "                    continue\n",
        "\n",
        "                sm[idx1][idx2] = self._sentence_similarity(sentences[idx1], sentences[idx2], stopwords=stopwords)\n",
        "\n",
        "        # Get Symmeric matrix\n",
        "        sm = get_symmetric_matrix(sm)\n",
        "\n",
        "        # Normalize matrix by column\n",
        "        norm = np.sum(sm, axis=0)\n",
        "        sm_norm = np.divide(sm, norm, where=norm != 0)  # this is ignore the 0 element in norm\n",
        "\n",
        "        return sm_norm\n",
        "\n",
        "    def _run_page_rank(self, similarity_matrix):\n",
        "\n",
        "        pr_vector = np.array([1] * len(similarity_matrix))\n",
        "\n",
        "        # Iteration\n",
        "        previous_pr = 0\n",
        "        for epoch in range(self.steps):\n",
        "            pr_vector = (1 - self.damping) + self.damping * np.matmul(similarity_matrix, pr_vector)\n",
        "            if abs(previous_pr - sum(pr_vector)) < self.min_diff:\n",
        "                break\n",
        "            else:\n",
        "                previous_pr = sum(pr_vector)\n",
        "\n",
        "        return pr_vector\n",
        "\n",
        "    def _get_sentence(self, index):\n",
        "\n",
        "        try:\n",
        "            return self.sentences[index]\n",
        "        except IndexError:\n",
        "            return \"\"\n",
        "\n",
        "    def get_top_sentences(self, number=5):\n",
        "\n",
        "        top_sentences = []\n",
        "\n",
        "        if self.pr_vector is not None:\n",
        "\n",
        "            sorted_pr = np.argsort(self.pr_vector)\n",
        "            sorted_pr = list(sorted_pr)\n",
        "            sorted_pr.reverse()\n",
        "\n",
        "            index = 0\n",
        "            for epoch in range(number):\n",
        "                sent = self.sentences[sorted_pr[index]]\n",
        "                sent = normalize_whitespace(sent)\n",
        "                top_sentences.append(sent)\n",
        "                index += 1\n",
        "\n",
        "        return top_sentences\n",
        "\n",
        "    def analyze(self, text, stop_words=None):\n",
        "        self.text_str = text\n",
        "        self.sentences = sent_tokenize(self.text_str)\n",
        "\n",
        "        tokenized_sentences = [word_tokenize(sent) for sent in self.sentences]\n",
        "\n",
        "        similarity_matrix = self._build_similarity_matrix(tokenized_sentences, stop_words)\n",
        "\n",
        "        self.pr_vector = self._run_page_rank(similarity_matrix)\n",
        "\n",
        "\n",
        "text_str = '''Junk foods taste good that’s why it is mostly liked by everyone of any age group especially kids and school going children. They generally ask for the junk food daily because they have been trend so by their parents from the childhood. They never have been discussed by their parents about the harmful effects of junk foods over health. According to the research by scientists, it has been found that junk foods have negative effects on the health in many ways. They are generally fried food found in the market in the packets. They become high in calories, high in cholesterol, low in healthy nutrients, high in sodium mineral, high in sugar, starch, unhealthy fat, lack of protein and lack of dietary fibers. Processed and junk foods are the means of rapid and unhealthy weight gain and negatively impact the whole body throughout the life. It makes able a person to gain excessive weight which is called as obesity. Junk foods tastes good and looks good however do not fulfil the healthy calorie requirement of the body. Some of the foods like french fries, fried foods, pizza, burgers, candy, soft drinks, baked goods, ice cream, cookies, etc are the example of high-sugar and high-fat containing foods. It is found according to the Centres for Disease Control and Prevention that Kids and children eating junk food are more prone to the type-2 diabetes. In type-2 diabetes our body become unable to regulate blood sugar level. Risk of getting this disease is increasing as one become more obese or overweight. It increases the risk of kidney failure. Eating junk food daily lead us to the nutritional deficiencies in the body because it is lack of essential nutrients, vitamins, iron, minerals and dietary fibers. It increases risk of cardiovascular diseases because it is rich in saturated fat, sodium and bad cholesterol. High sodium and bad cholesterol diet increases blood pressure and overloads the heart functioning. One who like junk food develop more risk to put on extra weight and become fatter and unhealthier. Junk foods contain high level carbohydrate which spike blood sugar level and make person more lethargic, sleepy and less active and alert. Reflexes and senses of the people eating this food become dull day by day thus they live more sedentary life. Junk foods are the source of constipation and other disease like diabetes, heart ailments, clogged arteries, heart attack, strokes, etc because of being poor in nutrition. Junk food is the easiest way to gain unhealthy weight. The amount of fats and sugar in the food makes you gain weight rapidly. However, this is not a healthy weight. It is more of fats and cholesterol which will have a harmful impact on your health. Junk food is also one of the main reasons for the increase in obesity nowadays.This food only looks and tastes good, other than that, it has no positive points. The amount of calorie your body requires to stay fit is not fulfilled by this food. For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats. Therefore, this can result in long-term illnesses like diabetes and high blood pressure. This may also result in kidney failure. Above all, you can get various nutritional deficiencies when you don’t consume the essential nutrients, vitamins, minerals and more. You become prone to cardiovascular diseases due to the consumption of bad cholesterol and fat plus sodium. In other words, all this interferes with the functioning of your heart. Furthermore, junk food contains a higher level of carbohydrates. It will instantly spike your blood sugar levels. This will result in lethargy, inactiveness, and sleepiness. A person reflex becomes dull overtime and they lead an inactive life. To make things worse, junk food also clogs your arteries and increases the risk of a heart attack. Therefore, it must be avoided at the first instance to save your life from becoming ruined.The main problem with junk food is that people don’t realize its ill effects now. When the time comes, it is too late. Most importantly, the issue is that it does not impact you instantly. It works on your overtime; you will face the consequences sooner or later. Thus, it is better to stop now.You can avoid junk food by encouraging your children from an early age to eat green vegetables. Their taste buds must be developed as such that they find healthy food tasty. Moreover, try to mix things up. Do not serve the same green vegetable daily in the same style. Incorporate different types of healthy food in their diet following different recipes. This will help them to try foods at home rather than being attracted to junk food.In short, do not deprive them completely of it as that will not help. Children will find one way or the other to have it. Make sure you give them junk food in limited quantities and at healthy periods of time.'''\n",
        "\n",
        "tr4sh = TextRank4Sentences()\n",
        "tr4sh.analyze(text_str)\n",
        "print(tr4sh.get_top_sentences(5))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "IT204 Lecture summariser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcecMPteibdoHiuTFke2bv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}